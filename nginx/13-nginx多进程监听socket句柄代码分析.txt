
1、从主函数main进行调用
src\core\nginx.c
int ngx_cdecl main(int argc, char *const *argv)
{
    if (ngx_process == NGX_PROCESS_SINGLE) {
        ngx_single_process_cycle(cycle);

    } else {
        ngx_master_process_cycle(cycle);
    }

}



2、master_process_cycle函数调用不同函数进行初始化
void
ngx_master_process_cycle(ngx_cycle_t *cycle)
{

           cycle = ngx_init_cycle(cycle);
            if (cycle == NULL) {
                cycle = (ngx_cycle_t *) ngx_cycle;
                continue;
            }
}


3、初始化生命周期函数
ngx_cycle_t *
ngx_init_cycle(ngx_cycle_t *old_cycle)
{
    if (ngx_open_listening_sockets(cycle) != NGX_OK) {
        goto failed;
    }

}




4、监听socket句柄
d:\TF卡\nginx-1.24.0\src\core\ngx_connection.c
ngx_int_t
ngx_open_listening_sockets(ngx_cycle_t *cycle)
{
     if (listen(s, ls[i].backlog) == -1) {
                err = ngx_socket_errno;
}

5、监听socket句柄监听事件



typedef struct {
#if (NGX_HAVE_ATOMIC_OPS) //  如果定义了NGX_HAVE_ATOMIC_OPS，表示系统支持原子操作
    ngx_atomic_t  *lock; //  指向原子锁的指针
#if (NGX_HAVE_POSIX_SEM) //  如果定义了NGX_HAVE_POSIX_SEM，表示系统支持POSIX信号量
    ngx_atomic_t  *wait; //  指向等待计数器的指针，用于记录等待锁的线程数
    ngx_uint_t     semaphore; //  信号量值，用于控制访问资源的线程数
    sem_t          sem; //  POSIX信号量对象
#endif
#else
    ngx_fd_t       fd; //  如果系统不支持原子操作，使用文件描述符作为锁
    u_char        *name; //  锁的名称，通常用于标识锁
#endif
    ngx_uint_t     spin; //  自旋次数，用于自旋锁的实现
} ngx_shmtx_t;



  检查互斥锁的当前状态     如果锁的值为0，表示锁未被占用     使用原子操作尝试将锁的值从0设置为当前进程ID (ngx_pid)  
  如果设置成功，表示成功获取锁，返回true     如果设置失败，表示锁已被其他进程占用，返回false
ngx_uint_t  ngx_shmtx_trylock(ngx_shmtx_t *mtx)
{
    return (*mtx->lock == 0 && ngx_atomic_cmp_set(mtx->lock, 0, ngx_pid)); 
    
}


ngx_int_t   ngx_trylock_accept_mutex(ngx_cycle_t *cycle)
{
    if (ngx_shmtx_trylock(&ngx_accept_mutex)) {//  尝试获取锁;
    }

    return NGX_OK;
}

nginx-1.24.0\src\event\ngx_event.c
void ngx_process_events_and_timers(ngx_cycle_t *cycle)
{
    if (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) {
                return;
      }
      //处理网络连接
      (void) ngx_process_events(cycle, timer, flags);

}

ngx_worker_process_cycle(ngx_cycle_t *cycle, void *data)
{
   ngx_process_events_and_timers(cycle);
}


6、accept等待连接
src\event\ngx_event_accept.c
void ngx_event_accept(ngx_event_t *ev)
{
       s = accept(lc->fd, &sa.sockaddr, &socklen);

        c = ngx_get_connection(s, ev->log);
        //释放锁
        ngx_shmtx_unlock(&ngx_accept_mutex);
       
        给每个客户分配内存池
        c->pool = ngx_create_pool(ls->pool_size, ev->log);
        if (c->pool == NULL) {
            ngx_close_accepted_connection(c);
            return;
        }

        if (socklen > (socklen_t) sizeof(ngx_sockaddr_t)) {
            socklen = sizeof(ngx_sockaddr_t);
        }

        c->sockaddr = ngx_palloc(c->pool, socklen);
        if (c->sockaddr == NULL) {
            ngx_close_accepted_connection(c);
            return;
        }

}






void
ngx_master_process_cycle(ngx_cycle_t *cycle)
{
  ngx_start_worker_processes(cycle, ccf->worker_processes,
                               NGX_PROCESS_RESPAWN);
    ngx_start_cache_manager_processes(cycle, 0);

}

static void
ngx_start_worker_processes(ngx_cycle_t *cycle, ngx_int_t n, ngx_int_t type)
{
    ngx_int_t  i;

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start worker processes");

    for (i = 0; i < n; i++) {

        ngx_spawn_process(cycle, ngx_worker_process_cycle,
                          (void *) (intptr_t) i, "worker process", type);

        ngx_pass_open_channel(cycle);
    }
}


创建进程
src\os\unix\ngx_process.c
ngx_pid_t ngx_spawn_process(ngx_cycle_t *cycle, ngx_spawn_proc_pt proc, void *data,
    char *name, ngx_int_t respawn)
{
     pid = fork();

    switch (pid) {

    case -1:
        ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                      "fork() failed while spawning \"%s\"", name);
        ngx_close_channel(ngx_processes[s].channel, cycle->log);
        return NGX_INVALID_PID;

    case 0:
        ngx_parent = ngx_pid;
        ngx_pid = ngx_getpid();
        proc(cycle, data);
        break;

    default:
        break;
    }
    return pid;
}

